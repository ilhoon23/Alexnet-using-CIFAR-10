{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.1\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-822be276cf6a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__version__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlayers\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmodels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlayers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconvolutional\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpreprocessing\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimage\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImageDataGenerator\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "from tensorflow.keras import datasets, layers, models, utils\n",
    "from keras.layers.convolutional import MaxPooling2D\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n",
    "train_images.shape, test_images.shape, train_images.shape[1:],train_images.dtype\n",
    "train_labels=utils.to_categorical(train_labels)\n",
    "test_labels=utils.to_categorical(test_labels)\n",
    "print(train_labels.shape, test_labels.shape)\n",
    "input_shape=train_images.shape[1:]\n",
    "print(input_shape)\n",
    "\n",
    "\n",
    "model = models.Sequential()\n",
    "layers.Dropout(0.5)\n",
    "model.add(layers.Conv2D(96, (5, 5),strides=1, activation='relu', input_shape=(32, 32, 3),padding='valid'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2),strides=1,padding='valid'))\n",
    "layers.Dropout(0.5)\n",
    "model.add(layers.Conv2D(256, (4, 4),strides=1, activation='relu',padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "layers.Dropout(0.5)\n",
    "model.add(layers.Conv2D(384, (3, 3),strides=1, activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "layers.Dropout(0.5)\n",
    "model.add(layers.Conv2D(384, (3, 3),strides=1, activation='relu', padding='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "layers.Dropout(0.5)\n",
    "model.add(layers.Conv2D(256, (3, 3),strides=1, activation='relu', paddi\n",
    "ng='same'))\n",
    "model.add(layers.BatchNormalization())\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Flatten())\n",
    "layers.Dropout(0.2)\n",
    "model.add(layers.Dense(1024, activation='relu',kernel_regularizer='l2'))\n",
    "model.add(layers.BatchNormalization())\n",
    "layers.Dropout(0.2)\n",
    "model.add(layers.Dense(1024, activation='relu',kernel_regularizer='l2'))\n",
    "model.add(layers.BatchNormalization())\n",
    "layers.Dropout(0.2)\n",
    "model.add(layers.Dense(10, activation='softmax'))\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])\n",
    "datagen = ImageDataGenerator(rotation_range=20, # randomly rotate images in the range (degrees, 0 to 180)\n",
    "                            width_shift_range=0.2,\n",
    "                            height_shift_range=0.2,\n",
    "                            horizontal_flip=True, # randomly flip images\n",
    "                            )\n",
    "datagen.fit(train_images)\n",
    "# Fit the model on the batches generated by datagen.flow().\n",
    "history = model.fit(datagen.flow(train_images, train_labels,batch_size=64),epochs=40, validation_data=(test_images,test_labels),workers=4)\n",
    "!mkdir -p saved_model\n",
    "model.save('saved_model/my_model')\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(history.history['loss'], 'y', label='train loss')\n",
    "plt.plot(history.history['val_loss'], 'r', label='test loss')\n",
    "plt.title('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "plt.plot(history.history['accuracy'], 'y', label='train acc')\n",
    "plt.plot(history.history['val_accuracy'], 'r', label='test acc')\n",
    "plt.title('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.legend(loc='upper left')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "import os\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "!unzip \"/content/drive/MyDrive/face.zip\"\n",
    "os.chdir (\"/content/downsized\")\n",
    "train_generator = datagen.flow_from_directory(\n",
    "'/content/downsized/test',\n",
    "class_mode='categorical',\n",
    "target_size=(32,32),\n",
    "batch_size=32\n",
    ")\n",
    "datagen_2=ImageDataGenerator()\n",
    "test_generator = datagen_2.flow_from_directory(\n",
    "'/content/downsized/train',\n",
    "class_mode='categorical',\n",
    "target_size=(32,32)\n",
    ")\n",
    "\n",
    "\n",
    "model = tf.keras.models.load_model('/content/saved_model/my_model')\n",
    "model.pop()\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "for layer in model.layers[:18]:\n",
    "layer.trainable = False\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])\n",
    "history_2 = model.fit(train_generator,epochs=100,validation_data=test_generator,workers=4)\n",
    "model = tf.keras.models.load_model('/content/saved_model/my_model')\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.pop()\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "for layer in model.layers[:14]:\n",
    "layer.trainable = False\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.0007, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])\n",
    "history_3 = model.fit(train_generator,epochs=100,validation_data=test_generator,workers=4)\n",
    "model = tf.keras.models.load_model('/content/saved_model/my_model')\n",
    "model.pop()\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "for layer in model.layers[:6]:\n",
    "layer.trainable = False\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer=optimizer, m\n",
    "etrics=[ 'accuracy' ])\n",
    "history_2 = model.fit(train_generator,epochs=100,validation_data=test_generator,workers=4)\n",
    "model.pop()\n",
    "model.add(layers.Dense(100, activation='softmax'))\n",
    "for layer in model.layers[:18]:\n",
    "layer.trainable = False\n",
    "model.layers[18].trainable=True\n",
    "model.summary()\n",
    "optimizer = Adam(lr=0.001, beta_1=0.9, beta_2=0.999, amsgrad=False)\n",
    "model.compile(loss= 'categorical_crossentropy' , optimizer=optimizer, metrics=[ 'accuracy' ])\n",
    "history_4 = model.fit(train_generator,epochs=100,validation_data=test_generator,workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
